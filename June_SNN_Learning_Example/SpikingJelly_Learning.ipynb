{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71322d8c",
   "metadata": {},
   "source": [
    "Forward @ every step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a655f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_seq.shape = torch.Size([4, 1, 3, 8, 8])\n",
      "tensor([[[[[1.3969e-01, 5.7241e-01, 1.3846e-01, 1.3894e-01, 6.3913e-01,\n",
      "            1.5672e-01, 7.8673e-01, 1.7763e-01],\n",
      "           [2.6963e-01, 9.1444e-02, 3.7533e-01, 2.1515e-01, 9.1215e-01,\n",
      "            6.8916e-01, 8.0322e-01, 8.6394e-01],\n",
      "           [4.4042e-01, 8.2779e-01, 1.6054e-01, 8.1819e-01, 3.4448e-01,\n",
      "            9.9448e-01, 9.9542e-02, 8.3467e-01],\n",
      "           [6.3582e-01, 6.0021e-01, 3.6065e-02, 3.7547e-02, 2.1857e-01,\n",
      "            9.5829e-01, 3.1024e-01, 3.1122e-01],\n",
      "           [7.9110e-02, 9.9801e-01, 5.5114e-01, 7.2318e-01, 7.3463e-01,\n",
      "            7.1943e-01, 9.5675e-01, 7.7413e-01],\n",
      "           [4.2640e-01, 1.7001e-01, 4.0806e-01, 7.2800e-01, 5.8326e-01,\n",
      "            9.2726e-01, 4.0268e-01, 1.3796e-01],\n",
      "           [8.1662e-01, 8.4596e-01, 2.1623e-02, 6.8984e-01, 2.4509e-02,\n",
      "            6.9714e-01, 4.3843e-01, 4.1443e-01],\n",
      "           [4.1302e-01, 5.8538e-01, 1.4243e-01, 9.0664e-02, 4.2742e-01,\n",
      "            7.0951e-01, 5.6198e-01, 3.8165e-01]],\n",
      "\n",
      "          [[4.1251e-01, 8.6943e-01, 6.8016e-02, 2.0927e-01, 5.5295e-01,\n",
      "            3.8588e-01, 7.6685e-01, 4.1569e-01],\n",
      "           [1.2208e-01, 1.9145e-01, 2.0864e-01, 4.7645e-01, 3.4492e-01,\n",
      "            3.1940e-01, 7.1791e-03, 9.7508e-01],\n",
      "           [5.5522e-01, 1.9163e-01, 9.3693e-01, 9.8033e-01, 5.8782e-01,\n",
      "            4.3583e-01, 5.2573e-01, 4.3377e-01],\n",
      "           [5.3120e-01, 1.3537e-01, 7.5319e-01, 7.5432e-02, 5.5000e-01,\n",
      "            6.8740e-01, 3.5536e-01, 1.4011e-01],\n",
      "           [1.0321e-01, 1.8125e-01, 5.6211e-01, 4.2077e-01, 6.0657e-01,\n",
      "            7.7427e-01, 1.3740e-02, 3.3145e-01],\n",
      "           [8.0920e-01, 1.3020e-01, 8.5741e-01, 4.4756e-01, 9.6548e-01,\n",
      "            4.6638e-02, 5.0013e-01, 4.9636e-01],\n",
      "           [4.0449e-01, 6.8289e-01, 3.2489e-01, 1.8996e-01, 3.0080e-01,\n",
      "            3.6874e-01, 2.4454e-01, 5.8371e-01],\n",
      "           [1.2220e-01, 4.5458e-01, 6.0289e-01, 7.6295e-01, 1.9482e-01,\n",
      "            7.5233e-01, 8.3205e-01, 3.2992e-01]],\n",
      "\n",
      "          [[4.7038e-02, 5.2503e-01, 9.4044e-01, 9.5873e-01, 2.4619e-01,\n",
      "            8.9642e-01, 9.4845e-01, 2.6158e-01],\n",
      "           [3.3596e-01, 1.6235e-01, 8.5924e-01, 5.0222e-01, 3.1627e-01,\n",
      "            9.8461e-01, 6.2884e-01, 9.2975e-01],\n",
      "           [3.7845e-01, 6.9343e-01, 9.3404e-01, 6.8976e-01, 7.2304e-01,\n",
      "            7.0582e-01, 4.0767e-01, 1.8342e-01],\n",
      "           [8.8854e-01, 2.5685e-01, 8.6229e-01, 2.5749e-01, 4.1258e-01,\n",
      "            6.5913e-02, 8.9474e-01, 5.3726e-03],\n",
      "           [5.3548e-01, 9.4255e-01, 1.6038e-01, 3.4672e-01, 3.9431e-01,\n",
      "            6.8248e-01, 5.5609e-01, 4.4702e-01],\n",
      "           [7.8793e-01, 2.1313e-01, 1.7840e-01, 7.0295e-02, 5.6348e-01,\n",
      "            6.0342e-01, 4.3483e-01, 5.4708e-01],\n",
      "           [1.6377e-01, 8.3542e-01, 2.2960e-01, 5.0565e-01, 4.7725e-01,\n",
      "            1.8764e-01, 5.3651e-01, 4.5297e-01],\n",
      "           [2.3666e-01, 5.5530e-01, 5.0354e-01, 7.8246e-01, 9.7869e-01,\n",
      "            6.4757e-01, 3.5826e-01, 5.1271e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[7.3228e-01, 2.5271e-01, 7.3984e-01, 5.4306e-01, 1.6307e-01,\n",
      "            8.7516e-01, 2.8957e-01, 2.9126e-01],\n",
      "           [5.7568e-02, 3.9191e-01, 1.6987e-01, 7.6761e-01, 9.8604e-01,\n",
      "            5.5204e-01, 3.5145e-01, 1.9442e-01],\n",
      "           [7.3881e-02, 5.5681e-01, 7.0082e-02, 8.7373e-01, 5.3367e-01,\n",
      "            6.9140e-01, 7.1718e-01, 3.6805e-01],\n",
      "           [2.0606e-01, 8.6673e-02, 3.6385e-01, 1.2256e-01, 6.4038e-01,\n",
      "            1.1448e-01, 7.8727e-01, 9.9459e-01],\n",
      "           [6.5734e-01, 4.4235e-01, 1.9367e-01, 4.9402e-02, 5.6079e-01,\n",
      "            2.3938e-02, 6.9340e-01, 4.2929e-02],\n",
      "           [5.4338e-01, 8.3774e-01, 9.1023e-01, 2.0189e-01, 7.3106e-02,\n",
      "            7.5460e-01, 5.8296e-01, 9.2711e-03],\n",
      "           [5.5944e-01, 4.1729e-01, 8.0455e-01, 1.2208e-01, 9.5866e-01,\n",
      "            3.2830e-01, 5.6023e-01, 2.2102e-02],\n",
      "           [1.8790e-01, 1.5635e-01, 2.0400e-01, 1.1861e-01, 7.4616e-01,\n",
      "            4.8378e-01, 1.4304e-01, 9.6838e-01]],\n",
      "\n",
      "          [[9.2790e-01, 3.3659e-01, 3.9030e-01, 7.9682e-01, 2.4603e-01,\n",
      "            2.6234e-01, 1.3786e-01, 4.6569e-01],\n",
      "           [1.8601e-01, 5.2817e-02, 7.3116e-01, 3.6330e-01, 5.7607e-01,\n",
      "            4.2793e-01, 4.5204e-01, 1.2147e-01],\n",
      "           [3.9319e-01, 5.4037e-01, 6.8538e-01, 7.1180e-01, 2.9833e-01,\n",
      "            2.1698e-01, 9.0171e-01, 7.1349e-01],\n",
      "           [9.9668e-01, 2.0248e-01, 2.6894e-01, 3.2882e-01, 5.8950e-01,\n",
      "            8.6455e-01, 5.7897e-02, 4.8363e-01],\n",
      "           [7.1636e-01, 4.8450e-01, 5.8203e-01, 1.2872e-01, 4.7382e-01,\n",
      "            7.3070e-01, 2.1685e-01, 6.0066e-01],\n",
      "           [5.0803e-01, 5.0888e-01, 5.0086e-01, 4.0473e-01, 9.0962e-01,\n",
      "            4.9825e-01, 7.7399e-01, 9.0719e-01],\n",
      "           [4.8327e-01, 1.3940e-01, 9.5101e-01, 6.2851e-01, 8.4460e-01,\n",
      "            4.4036e-01, 7.4263e-01, 2.1609e-01],\n",
      "           [9.9352e-01, 8.4418e-01, 5.5735e-01, 5.8534e-01, 7.5101e-01,\n",
      "            4.5558e-01, 4.2226e-01, 6.9335e-01]],\n",
      "\n",
      "          [[6.6705e-01, 6.6196e-01, 9.7180e-01, 6.6245e-02, 7.6746e-02,\n",
      "            1.8303e-01, 1.7616e-01, 6.2789e-01],\n",
      "           [1.7347e-01, 2.9169e-01, 3.0237e-02, 7.1808e-01, 9.2460e-01,\n",
      "            5.3540e-01, 5.8083e-01, 5.2278e-01],\n",
      "           [8.8078e-01, 2.2475e-01, 7.6635e-01, 5.5115e-01, 6.6950e-01,\n",
      "            4.2858e-01, 9.7821e-01, 7.7895e-01],\n",
      "           [9.0294e-01, 1.9485e-01, 1.8625e-01, 4.2146e-01, 8.4669e-01,\n",
      "            4.6928e-01, 4.8221e-01, 3.4615e-01],\n",
      "           [7.6806e-01, 2.2805e-01, 6.7616e-01, 5.1026e-01, 5.5736e-01,\n",
      "            8.9040e-01, 6.1887e-01, 7.6549e-01],\n",
      "           [7.0105e-01, 6.3093e-02, 3.5207e-01, 4.3650e-01, 1.0782e-01,\n",
      "            1.6761e-01, 4.7941e-01, 3.4766e-01],\n",
      "           [7.0225e-01, 4.3653e-01, 7.6931e-01, 7.6141e-01, 8.9611e-01,\n",
      "            9.2912e-02, 4.3204e-01, 5.3431e-01],\n",
      "           [4.6260e-01, 1.4820e-01, 2.0456e-01, 4.8251e-01, 3.1389e-01,\n",
      "            7.1501e-01, 1.1835e-01, 7.0383e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[1.1332e-01, 4.2405e-01, 1.2411e-02, 2.8834e-01, 9.5472e-02,\n",
      "            2.4560e-01, 5.5897e-02, 4.3617e-01],\n",
      "           [9.9042e-01, 4.6744e-01, 5.8628e-03, 4.0314e-01, 9.2865e-01,\n",
      "            9.5361e-01, 5.7779e-01, 7.5023e-01],\n",
      "           [9.6654e-03, 4.7625e-01, 4.6715e-01, 7.7137e-02, 7.4005e-01,\n",
      "            4.1867e-01, 1.2011e-01, 8.9959e-01],\n",
      "           [2.7555e-01, 4.8207e-01, 9.6526e-01, 3.6951e-01, 4.3338e-01,\n",
      "            2.8094e-01, 3.7035e-01, 4.7826e-01],\n",
      "           [5.1035e-01, 2.3597e-01, 8.5701e-01, 9.9502e-01, 6.1016e-02,\n",
      "            8.1556e-01, 3.4623e-02, 6.2753e-01],\n",
      "           [1.8585e-02, 4.4620e-01, 2.3902e-01, 9.8720e-02, 4.4598e-01,\n",
      "            5.6967e-01, 9.7770e-01, 2.8788e-01],\n",
      "           [3.1419e-01, 1.8967e-01, 2.4374e-01, 6.5496e-01, 2.0060e-01,\n",
      "            8.3306e-01, 6.6120e-01, 7.0633e-01],\n",
      "           [7.9633e-01, 3.2382e-01, 8.2229e-01, 9.0778e-01, 3.8620e-01,\n",
      "            1.0258e-01, 3.7698e-01, 8.4525e-01]],\n",
      "\n",
      "          [[2.4269e-01, 8.2355e-01, 6.2237e-01, 7.5734e-01, 8.8386e-01,\n",
      "            9.4787e-01, 9.9547e-01, 9.9176e-01],\n",
      "           [9.6747e-01, 9.5478e-01, 4.0070e-01, 4.9421e-01, 1.8994e-01,\n",
      "            3.6345e-01, 6.4228e-01, 2.6975e-01],\n",
      "           [7.2077e-01, 8.3372e-01, 1.1517e-01, 1.8544e-01, 5.0866e-01,\n",
      "            6.4528e-01, 2.8479e-01, 4.4310e-02],\n",
      "           [6.9059e-01, 4.0406e-01, 9.5963e-01, 5.2016e-01, 8.1248e-01,\n",
      "            1.8878e-01, 6.9075e-01, 5.3936e-01],\n",
      "           [3.8972e-02, 6.2310e-02, 9.4773e-01, 3.1579e-01, 7.1552e-01,\n",
      "            4.4158e-01, 5.6581e-01, 6.5355e-02],\n",
      "           [9.9697e-01, 7.8754e-01, 7.2177e-01, 3.0789e-02, 8.6783e-01,\n",
      "            6.4317e-01, 8.0211e-01, 6.6955e-01],\n",
      "           [6.3007e-01, 3.7525e-01, 4.5749e-01, 6.3810e-01, 3.4722e-01,\n",
      "            7.1066e-01, 2.2334e-01, 6.4774e-01],\n",
      "           [1.3315e-01, 6.9392e-01, 1.1831e-01, 8.2701e-01, 3.1861e-01,\n",
      "            5.9801e-01, 7.4969e-01, 6.4233e-01]],\n",
      "\n",
      "          [[4.6800e-01, 9.3429e-01, 6.0968e-01, 4.5085e-01, 4.3626e-01,\n",
      "            4.2170e-01, 5.1403e-01, 1.4746e-01],\n",
      "           [2.9247e-01, 7.6977e-01, 5.1040e-01, 8.2222e-01, 1.3213e-01,\n",
      "            6.0115e-01, 4.0572e-01, 6.9203e-01],\n",
      "           [6.1497e-02, 3.6330e-01, 3.2651e-01, 7.8633e-01, 3.5777e-01,\n",
      "            5.0341e-01, 2.2561e-01, 9.0212e-01],\n",
      "           [8.2376e-01, 4.4856e-01, 8.1305e-01, 6.5098e-01, 5.3543e-01,\n",
      "            6.6339e-01, 8.2747e-01, 2.7150e-01],\n",
      "           [8.8754e-01, 5.5252e-01, 6.5084e-01, 3.8202e-01, 7.2848e-02,\n",
      "            8.7908e-01, 9.2033e-01, 1.4565e-01],\n",
      "           [4.9628e-01, 2.8630e-01, 4.7113e-02, 2.7781e-01, 9.7744e-03,\n",
      "            8.5049e-01, 6.2897e-01, 6.4788e-01],\n",
      "           [3.9952e-01, 9.1226e-02, 4.1178e-01, 1.3749e-01, 5.5650e-01,\n",
      "            8.0296e-01, 2.5846e-01, 6.1457e-01],\n",
      "           [6.6267e-01, 7.3399e-01, 6.5556e-01, 5.5354e-01, 3.9073e-01,\n",
      "            3.2970e-01, 2.1052e-01, 6.9341e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[8.8256e-01, 7.1906e-01, 8.5472e-01, 3.6292e-01, 7.4836e-01,\n",
      "            7.0996e-01, 4.5984e-01, 2.7250e-01],\n",
      "           [4.1127e-01, 8.4824e-01, 5.3433e-01, 2.2018e-01, 9.9728e-03,\n",
      "            8.4653e-01, 6.7691e-01, 5.1784e-01],\n",
      "           [3.7382e-01, 1.3945e-01, 2.5144e-01, 2.3005e-01, 9.9508e-01,\n",
      "            1.7323e-01, 6.7521e-01, 2.1773e-01],\n",
      "           [7.8332e-01, 3.9529e-01, 4.1897e-01, 9.6968e-01, 6.8360e-01,\n",
      "            6.6964e-01, 5.6266e-01, 8.7347e-01],\n",
      "           [4.5917e-01, 3.0417e-01, 5.7575e-01, 5.7217e-02, 5.9546e-01,\n",
      "            7.9722e-01, 8.3726e-01, 3.1137e-02],\n",
      "           [5.8580e-02, 4.5621e-01, 9.2486e-01, 6.9664e-01, 8.3270e-02,\n",
      "            2.4224e-01, 2.7913e-01, 2.7085e-01],\n",
      "           [2.3453e-01, 6.4508e-02, 9.4546e-01, 5.8957e-01, 9.1868e-01,\n",
      "            9.0068e-01, 8.8238e-01, 4.9401e-01],\n",
      "           [1.3986e-01, 1.3465e-01, 9.6614e-01, 6.4775e-01, 6.0026e-01,\n",
      "            5.4934e-01, 1.9126e-01, 8.3431e-01]],\n",
      "\n",
      "          [[2.7427e-01, 9.3665e-02, 4.6845e-01, 9.8889e-02, 3.1181e-01,\n",
      "            8.1111e-01, 9.7231e-01, 1.2930e-01],\n",
      "           [7.2338e-01, 3.8018e-01, 3.5614e-01, 8.9299e-01, 9.3766e-01,\n",
      "            4.0996e-01, 3.1453e-04, 9.2081e-01],\n",
      "           [3.1802e-01, 2.1275e-01, 5.0838e-01, 2.0257e-01, 9.9455e-01,\n",
      "            4.5029e-01, 7.3812e-01, 2.6386e-02],\n",
      "           [1.3730e-01, 9.4612e-02, 4.1727e-03, 7.7367e-01, 6.9582e-01,\n",
      "            7.5302e-01, 2.9360e-01, 8.6679e-01],\n",
      "           [4.2971e-01, 7.1391e-01, 6.3872e-01, 6.2110e-02, 2.1942e-01,\n",
      "            2.1124e-01, 8.7813e-01, 8.9481e-01],\n",
      "           [4.5513e-01, 8.2443e-01, 5.0487e-01, 2.3115e-01, 9.1114e-01,\n",
      "            4.2399e-01, 4.2313e-01, 6.0786e-01],\n",
      "           [8.5820e-01, 9.7259e-02, 2.3939e-01, 4.2771e-01, 2.6503e-01,\n",
      "            7.9821e-01, 9.5574e-01, 9.7242e-01],\n",
      "           [6.2124e-01, 9.0852e-01, 6.6858e-01, 4.1058e-01, 6.5067e-01,\n",
      "            5.3261e-01, 2.4678e-03, 2.3295e-01]],\n",
      "\n",
      "          [[1.6909e-01, 5.9535e-02, 2.5458e-02, 4.6368e-01, 7.7051e-01,\n",
      "            8.9542e-01, 8.8950e-01, 5.2516e-01],\n",
      "           [3.3121e-01, 2.7026e-01, 5.9105e-01, 6.7029e-01, 6.6592e-01,\n",
      "            6.9429e-01, 3.1668e-01, 8.1375e-01],\n",
      "           [9.1133e-01, 6.2653e-02, 9.6101e-01, 3.9557e-01, 9.0568e-01,\n",
      "            7.1000e-01, 2.2587e-01, 8.2692e-01],\n",
      "           [8.9704e-01, 7.8192e-01, 4.1502e-01, 4.9522e-01, 2.7635e-01,\n",
      "            4.6709e-02, 2.7900e-01, 6.1776e-01],\n",
      "           [1.0272e-01, 3.6050e-01, 7.7427e-01, 3.2447e-01, 2.8209e-01,\n",
      "            5.9270e-01, 3.5875e-01, 9.5753e-01],\n",
      "           [9.7251e-01, 7.3304e-01, 3.9616e-01, 6.1119e-01, 5.3733e-01,\n",
      "            7.1991e-01, 2.3834e-01, 6.1160e-01],\n",
      "           [1.3909e-01, 6.8031e-01, 4.1726e-01, 2.4200e-02, 8.5103e-01,\n",
      "            2.8062e-01, 8.3730e-01, 6.9270e-01],\n",
      "           [9.8513e-01, 7.0351e-01, 4.5921e-01, 9.5386e-01, 4.0533e-01,\n",
      "            8.4885e-01, 7.8350e-01, 8.6927e-01]]]]])\n",
      "y_seq.shape = torch.Size([4, 1, 3, 8, 8])\n",
      "tensor([[[[[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0., 0., 0., 0., 0.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0., 0., 0., 0., 0., 1., 1., 0.],\n",
      "           [0., 0., 0., 0., 1., 1., 1., 1.],\n",
      "           [0., 1., 0., 1., 0., 1., 0., 1.],\n",
      "           [0., 0., 0., 0., 0., 1., 1., 1.],\n",
      "           [0., 1., 0., 0., 1., 0., 1., 0.],\n",
      "           [0., 1., 1., 0., 0., 1., 0., 0.],\n",
      "           [1., 1., 0., 0., 0., 1., 0., 0.],\n",
      "           [0., 0., 0., 0., 1., 1., 0., 1.]],\n",
      "\n",
      "          [[1., 1., 0., 1., 0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "           [0., 0., 1., 1., 0., 0., 1., 1.],\n",
      "           [1., 0., 1., 0., 1., 1., 0., 0.],\n",
      "           [0., 0., 1., 0., 1., 1., 0., 0.],\n",
      "           [1., 0., 1., 0., 1., 0., 1., 1.],\n",
      "           [0., 0., 1., 0., 1., 0., 0., 0.],\n",
      "           [1., 1., 1., 1., 0., 1., 1., 1.]],\n",
      "\n",
      "          [[0., 1., 1., 1., 0., 1., 1., 0.],\n",
      "           [0., 0., 0., 1., 1., 1., 1., 1.],\n",
      "           [1., 0., 1., 1., 1., 1., 1., 0.],\n",
      "           [1., 0., 1., 0., 1., 0., 1., 0.],\n",
      "           [1., 1., 0., 0., 0., 1., 1., 1.],\n",
      "           [1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "           [0., 1., 0., 1., 1., 0., 0., 0.],\n",
      "           [0., 0., 0., 1., 1., 1., 0., 0.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "           [1., 0., 0., 1., 0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "           [1., 1., 1., 0., 1., 0., 0., 0.],\n",
      "           [1., 0., 1., 1., 0., 1., 0., 1.],\n",
      "           [0., 0., 0., 1., 1., 0., 1., 0.],\n",
      "           [0., 0., 1., 1., 1., 0., 1., 1.],\n",
      "           [1., 1., 1., 1., 0., 0., 1., 0.]],\n",
      "\n",
      "          [[0., 0., 1., 0., 1., 1., 1., 1.],\n",
      "           [1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "           [1., 1., 0., 0., 1., 1., 0., 0.],\n",
      "           [0., 0., 0., 0., 0., 0., 1., 1.],\n",
      "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "           [0., 1., 0., 0., 0., 1., 0., 0.],\n",
      "           [1., 1., 0., 1., 0., 1., 1., 1.],\n",
      "           [0., 0., 0., 0., 1., 0., 0., 0.]],\n",
      "\n",
      "          [[1., 0., 0., 0., 0., 0., 0., 1.],\n",
      "           [0., 1., 1., 0., 0., 0., 0., 0.],\n",
      "           [0., 1., 0., 0., 0., 0., 0., 1.],\n",
      "           [0., 0., 0., 1., 0., 1., 0., 0.],\n",
      "           [0., 0., 1., 1., 1., 0., 0., 0.],\n",
      "           [0., 0., 0., 0., 0., 1., 1., 1.],\n",
      "           [1., 0., 1., 0., 0., 1., 1., 1.],\n",
      "           [1., 1., 1., 0., 0., 0., 0., 1.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[1., 0., 1., 1., 1., 0., 0., 1.],\n",
      "           [0., 1., 1., 0., 0., 1., 1., 1.],\n",
      "           [0., 0., 0., 0., 0., 0., 1., 1.],\n",
      "           [0., 0., 0., 1., 0., 0., 0., 1.],\n",
      "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "           [1., 0., 1., 0., 0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "           [0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "\n",
      "          [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "           [0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "           [0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "           [0., 0., 0., 1., 1., 0., 0., 0.],\n",
      "           [1., 1., 1., 0., 0., 0., 1., 1.],\n",
      "           [1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "           [0., 1., 0., 1., 0., 1., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0., 0., 1., 1., 1., 0.],\n",
      "           [1., 0., 0., 1., 0., 1., 0., 1.],\n",
      "           [0., 0., 1., 1., 1., 1., 0., 0.],\n",
      "           [1., 1., 1., 0., 0., 0., 1., 1.],\n",
      "           [0., 0., 0., 0., 0., 1., 1., 1.],\n",
      "           [1., 1., 0., 1., 1., 0., 0., 0.],\n",
      "           [0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "           [0., 0., 0., 1., 0., 1., 1., 0.]]]]])\n",
      "Parameters: step_mode=s, v_threshold=1.0, v_reset=0.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from spikingjelly.activation_based import neuron\n",
    "\n",
    "net_s = neuron.IFNode(step_mode='s')\n",
    "T = 4\n",
    "N = 1\n",
    "C = 3\n",
    "H = 8\n",
    "W = 8\n",
    "x_seq = torch.rand([T, N, C, H, W])\n",
    "print('x_seq.shape =', x_seq.shape)\n",
    "print(x_seq)\n",
    "y_seq = []\n",
    "for t in range(T):\n",
    "    x = x_seq[t]  # x.shape = [N, C, H, W]\n",
    "    y = net_s(x)  # y.shape = [N, C, H, W]\n",
    "    y_seq.append(y.unsqueeze(0))\n",
    "\n",
    "y_seq = torch.cat(y_seq)\n",
    "print('y_seq.shape =', y_seq.shape)\n",
    "print(y_seq)\n",
    "print(f\"Parameters: step_mode={net_s.step_mode}, v_threshold={net_s.v_threshold}, v_reset={net_s.v_reset}\")\n",
    "# y_seq.shape = [T, N, C, H, W]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80610cd9",
   "metadata": {},
   "source": [
    "Forward @ multi-time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff38ba89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_seq.shape = torch.Size([4, 1, 3, 8, 8])\n",
      "y_seq.shape = torch.Size([4, 1, 3, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from spikingjelly.activation_based import neuron, functional\n",
    "\n",
    "net_s = neuron.IFNode(step_mode='s')\n",
    "T = 4\n",
    "N = 1\n",
    "C = 3\n",
    "H = 8\n",
    "W = 8\n",
    "x_seq = torch.rand(T, N, C, H, W) \n",
    "print('x_seq.shape =', x_seq.shape)\n",
    "# print(x_seq)\n",
    "y_seq = functional.multi_step_forward(x_seq, net_s)   \n",
    "print('y_seq.shape =', y_seq.shape)\n",
    "# print(y_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2945d7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_seq.shape = torch.Size([4, 1, 3, 8, 8])\n",
      "y_seq_m.shape = torch.Size([4, 1, 3, 8, 8])\n",
      "neuron shape:  torch.Size([1, 3, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from spikingjelly.activation_based import neuron\n",
    "\n",
    "net_m = neuron.IFNode(step_mode='m')\n",
    "net_s = neuron.IFNode(step_mode='s')\n",
    "T = 4\n",
    "N = 1\n",
    "C = 3\n",
    "H = 8\n",
    "W = 8\n",
    "x_seq = torch.rand(T, N, C, H, W) \n",
    "print('x_seq.shape =', x_seq.shape)\n",
    "# print(x_seq)\n",
    "y_seq_m = net_m(x_seq)  # y_seq_m.shape = [T, N, C, H, W]\n",
    "print('y_seq_m.shape =', y_seq_m.shape)\n",
    "print('neuron shape: ', net_m.v.shape)\n",
    "# print(y_seq_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0434d5",
   "metadata": {},
   "source": [
    "Propagate layer-by-layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7425e94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "net_structure Sequential(\n",
      "  (0): Linear(in_features=8, out_features=4, bias=True)\n",
      "  (1): IFNode(\n",
      "    v_threshold=1.0, v_reset=0.0, detach_reset=False, step_mode=m, backend=torch\n",
      "    (surrogate_function): Sigmoid(alpha=4.0, spiking=True)\n",
      "  )\n",
      "  (2): Linear(in_features=4, out_features=2, bias=True)\n",
      "  (3): IFNode(\n",
      "    v_threshold=1.0, v_reset=0.0, detach_reset=False, step_mode=m, backend=torch\n",
      "    (surrogate_function): Sigmoid(alpha=4.0, spiking=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Linear' object has no attribute 'v'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     26\u001b[0m     y_seq_layer_by_layer \u001b[38;5;241m=\u001b[39m layer_i(y_seq_layer_by_layer) \n\u001b[0;32m---> 27\u001b[0m v\u001b[38;5;241m.\u001b[39mappend(\u001b[43mlayer_i\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mv\u001b[49m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/SNN/lib/python3.10/site-packages/torch/nn/modules/module.py:1940\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1938\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1939\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1940\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1941\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1942\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Linear' object has no attribute 'v'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from spikingjelly.activation_based import neuron, functional, layer\n",
    "T = 4\n",
    "N = 2\n",
    "C = 8\n",
    "x_seq = torch.rand([T, N, C]) * 64.\n",
    "\n",
    "net = nn.Sequential(\n",
    "    layer.Linear(C, 4),\n",
    "    neuron.IFNode(step_mode='m'),\n",
    "    layer.Linear(4, 2),\n",
    "    neuron.IFNode(step_mode='m')\n",
    ")\n",
    "print('net_structure', net)\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_seq_layer_by_layer = x_seq\n",
    "    for i in range(net.__len__()):\n",
    "        layer_i = net[i]\n",
    "        if isinstance(layer_i, neuron.IFNode):\n",
    "            y_seq_layer_by_layer = functional.multi_step_forward(y_seq_layer_by_layer, layer_i)\n",
    "        else:\n",
    "            y_seq_layer_by_layer = layer_i(y_seq_layer_by_layer) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
